# -*- coding: utf-8 -*-
"""exam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SEcgZhC7KF-aMGh5QTTn_2NDjghAzQ_5

# Préparation du Dataset
"""

from datasets import load_dataset
ds = load_dataset("PedroSampaio/fruits-360")#, split="train+test")

ds

ds['train'][1]

from datasets import DatasetDict

ds

train = ds['train']
test = DatasetDict()
test = ds['test']

train

train_labels = train['label']

# Vérifier les valeurs minimales et maximales des labels
min_label = min(train['label'])
max_label = max(train['label'])
print(f"Label min: {min_label}, Label max: {max_label}")

from transformers import AutoImageProcessor
model_name = 'google/vit-base-patch16-224-in21k'
image_processor = AutoImageProcessor.from_pretrained(model_name)

from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor
normalize = Normalize(image_processor.image_mean, std=image_processor.image_std)
size = (image_processor.size['shortest_edge'] if 'shortest_edge' in image_processor.size else (image_processor.size['height'], image_processor.size['width']))
_transform = Compose([RandomResizedCrop(size), ToTensor(), normalize])

def transform(example):
    # Convertir les images en tenseurs et les stocker dans 'pixel_values'
    example['pixel_values'] = [_transform(img.convert('RGB')) for img in example['image']]
    # Supprimer la clé 'image' pour libérer de la mémoire
    del example['image']
    return example

ds

# Appliquer la transformation au dataset
dst = ds.map(transform, batched=True)

dst

from transformers import DefaultDataCollator
data_collator = DefaultDataCollator()

import evaluate
accuracy = evaluate.load('accuracy')

import numpy as np

def compute_metrics(eval_pred):
  prediction, label = eval_pred
  prediction = np.argmax(prediction, axis=1)
  return accuracy.compute(predictions=prediction, references=label)

from transformers import AutoModelForImageClassification

model = AutoModelForImageClassification.from_pretrained(
    model_name,
    num_labels=113,  # Remplacez par le nombre de classes dans votre dataset
    ignore_mismatched_sizes=True  # Ignore les mismatches de taille si nécessaire
)



from transformers import Trainer, TrainingArguments

# Gel des autres couches du modèle
for param in model.parameters():
    param.requires_grad = False

# Déverrouillage des paramètres de la dernière couche
for param in model.classifier.parameters():  # Supposant que la dernière couche s'appelle 'classifier'
    param.requires_grad = True

# Configuration des arguments d'entraînement
training_args = TrainingArguments(
    output_dir='Fruit_classification',  # Dossier de sortie
    per_device_train_batch_size=64,     # Taille du batch augmentée
    gradient_accumulation_steps=1,      # Pas d'accumulation de gradients
    num_train_epochs=3,                 # Nombre d'époques réduit
    fp16=True,                          # Activer la précision mixte
    dataloader_num_workers=4,           # Optimiser le chargement des données
    evaluation_strategy='epoch',        # Évaluer à la fin de chaque époque
    save_strategy='epoch',              # Sauvegarder à la fin de chaque époque
    learning_rate=5e-5,                 # Taux d'apprentissage
    remove_unused_columns=False,        # Ne pas supprimer les colonnes inutilisées
    report_to="none"                    # Désactiver les rapports externes
)

# Initialisation du Trainer
trainer = Trainer(
    model=model,                        # Le modèle à entraîner
    args=training_args,                 # Les arguments d'entraînement
    train_dataset=dst['train'],         # Dataset d'entraînement (67 690 images)
    eval_dataset=dst['test'],           # Dataset d'évaluation
    compute_metrics=compute_metrics,    # Fonction pour calculer les métriques
    tokenizer=image_processor           # Tokenizer (ou processeur d'images)
)

trainer.train()

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Obtenir les prédictions
predictions = trainer.predict(dst['test'])
y_pred = np.argmax(predictions.predictions, axis=1)
y_true = dst['test']["labels"]

# Afficher le rapport de classification
print(classification_report(y_true, y_pred))

# Afficher la matrice de confusion
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
plt.xlabel("Prédictions")
plt.ylabel("Vérités")
plt.title("Matrice de confusion")
plt.show()

from PIL import Image
import torch

# Charger une image et la transformer
image_path = "nouvelle_image.jpg"  # Remplace avec ton image
image = Image.open(image_path)
inputs = image_processor(images=image, return_tensors="pt")

# Prédiction
model.eval()
with torch.no_grad():
    outputs = model(**inputs)
    logits = outputs.logits
    predicted_class = torch.argmax(logits, dim=-1).item()

print(f"Classe prédite : {predicted_class}")

from flask import Flask, request, jsonify
from PIL import Image
import torch

app = Flask(__name__)

# Charger le modèle
model = AutoModelForImageClassification.from_pretrained("mon_modele_fruit_classification")
model.eval()

@app.route('/predict', methods=['POST'])
def predict():
    file = request.files['file']
    image = Image.open(file)
    inputs = image_processor(images=image, return_tensors="pt")

    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        predicted_class = torch.argmax(logits, dim=-1).item()

    return jsonify({'classe_predite': predicted_class})

if __name__ == '__main__':
    app.run(debug=True)